# ============================================================================
# OpenObserve Alert Template - Complete Reference Guide
# ============================================================================
# This template provides a comprehensive reference for creating OpenObserve alerts
# with all available fields and their validation requirements.
#
# Version: v1alpha1
# Last Updated: 2024-11-29
#
# IMPORTANT NOTES:
# - Read all comments carefully to understand field requirements and constraints
# - Fields marked (Required) must be present for the alert to be valid
# - Fields marked (Optional) can be omitted and will use default values
# - Some field combinations have special validation rules (see below)
# ============================================================================

apiVersion: openobserve.ai/v1alpha1
kind: OpenObserveAlert
metadata:
  name: <alert-resource-name>  # Kubernetes resource name (lowercase, alphanumeric, hyphens)
  namespace: <namespace>        # Target namespace for the alert resource
spec:
  # ============================================================================
  # CONFIGURATION REFERENCE (Required)
  # Links this alert to an OpenObserve instance configuration
  # ============================================================================
  configRef:
    name: <config-name>         # Name of the OpenObserveConfig resource (Required)
    namespace: <namespace>      # Namespace of the config (Optional, defaults to alert namespace)

  # ============================================================================
  # ALERT IDENTIFICATION & BASIC SETTINGS
  # ============================================================================

  # Alert name in OpenObserve (Required)
  # - Pattern: ^[a-zA-Z0-9_-]+$ (no spaces allowed)
  # - Must be unique within the organization
  # - This is the internal name in OpenObserve, different from the K8s resource name
  # - Example: "high_error_rate", "disk_usage_alert", "api_latency_p99"
  name: "alert_name_without_spaces"

  # Enable/disable the alert (Optional, defaults to true)
  # - When false, alert won't be evaluated but remains in the system
  # - Useful for temporarily disabling alerts during maintenance
  enabled: true

  # Alert description (Optional but recommended)
  # - Human-readable description of what this alert monitors
  # - Max length: 1000 characters
  # - Should explain: what it monitors, why it matters, what action to take
  description: "Monitors error rates in the application logs and triggers when threshold is exceeded"

  # ============================================================================
  # STREAM CONFIGURATION
  # Defines which data stream this alert monitors
  # ============================================================================

  # Stream to monitor (Optional, defaults to "default")
  # - Must exist in OpenObserve unless SKIP_STREAM_VALIDATION=true
  # - Examples: "application_logs", "nginx_access", "kubernetes_events"
  streamName: "default"

  # Stream type (Optional, defaults to "logs")
  # - Allowed values: logs, metrics, traces
  # - Must be "metrics" for PromQL queries
  # - Determines available query functions and operators
  streamType: "logs"

  # ============================================================================
  # ALERT EXECUTION MODE
  # ============================================================================

  # Real-time alert flag (Optional, defaults to false)
  # - When true:
  #   * Alert triggers immediately on matching events (no delay)
  #   * aggregation must be null (no grouping/counting allowed)
  #   * query type must be "custom" (not SQL or PromQL)
  #   * Best for critical security or error conditions
  # - When false:
  #   * Alert evaluated on schedule defined by triggerCondition
  #   * Can use aggregation for counting/grouping
  #   * Better for trend-based alerts
  isRealTime: false

  # ============================================================================
  # FOLDER ORGANIZATION
  # Organize alerts in folders for better management
  # ============================================================================

  # Folder ID for organizing alerts (Optional, defaults to "default")
  # - Use existing folder ID from OpenObserve
  # - Useful for organizing by team/service/severity
  folderId: "default"

  # Folder name for auto-creation (Optional)
  # - If specified and folder doesn't exist, it will be created automatically
  # - Takes precedence over folderId if both are specified
  # - Examples: "production_alerts", "team_platform", "critical_alerts"
  folderName: "production_alerts"

  # ============================================================================
  # QUERY CONDITION (Required)
  # Defines the query logic for the alert - the heart of alert configuration
  # ============================================================================
  queryCondition:
    # Query type (Required)
    # - "custom": Simple filter conditions with optional aggregation
    # - "sql": Complex SQL queries with full query capabilities
    # - "promql": Prometheus-style metric queries (requires streamType: metrics)
    type: "custom"

    # ==========================================
    # OPTION 1: CUSTOM QUERY TYPE
    # Use for simple filtering and aggregation
    # ==========================================

    # AGGREGATION (Optional, null for real-time alerts)
    # Groups and summarizes data before evaluation
    aggregation:
      # Fields to group results by (Optional)
      # - Creates separate alert instances for each unique combination
      # - Example: ["host", "service"] creates alerts per host-service pair
      groupBy:
        - "field1"
        - "field2"

      # Aggregation function (Optional)
      # - count: Number of matching records
      # - sum: Total of numeric field values
      # - avg: Average of numeric field values
      # - min: Minimum numeric value
      # - max: Maximum numeric value
      function: "count"

      # HAVING clause for post-aggregation filtering (Optional)
      # Filters aggregated results (like SQL HAVING)
      having:
        column: "_count"         # Column to evaluate (use _count for count function)
        operator: ">="          # Operators: =, !=, >, >=, <, <=
        value: 10               # Threshold value
        ignoreCase: false       # Case sensitivity (for string comparisons)

    # CONDITIONS (Optional for custom type)
    # Defines filter criteria for selecting records
    # Supports nested conditions for complex logical expressions
    conditions:
      # Top-level logical operator - can use "or" for nested conditions
      # This example shows: (job > 11) OR ((level = 111) OR (log = 122))
      or:
        # First condition: simple comparison
        - column: "job"
          operator: ">"
          value: "11"
          ignore_case: false

        # Second condition: nested OR group
        - or:
            - column: "level"
              operator: "="
              value: "111"
              ignore_case: true
            - column: "log"
              operator: "="
              value: "122"
              ignore_case: true

      # Available operators:
      # - Equality: =, !=
      # - Numeric: >, >=, <, <=
      # - String: contains, not_contains
      # - Special: starts_with, ends_with (if supported)

    # ==========================================
    # OPTION 2: SQL QUERY TYPE
    # Use for complex queries with joins, subqueries, etc.
    # ==========================================

    # SQL query (Required for sql type, empty string otherwise)
    # - Standard SQL syntax with some OpenObserve extensions
    # - Table name is always "stream"
    # - Can reference any field in the stream
    # - Supports: SELECT, WHERE, GROUP BY, HAVING, ORDER BY, LIMIT
    # - Time functions: now(), from_unixtime(), etc.
    sql: |
      SELECT
        host,
        service,
        COUNT(*) as error_count,
        MAX(response_time) as max_response_time
      FROM stream
      WHERE
        level = 'ERROR'
        AND _timestamp >= now() - INTERVAL '1 hour'
      GROUP BY host, service
      HAVING error_count > 10
      ORDER BY error_count DESC
      LIMIT 100

    # VRL Function (Optional, only for SQL type)
    # Vector Remap Language for transforming query results
    # IMPORTANT: For SQL queries, VRL functions are BASE64 ENCODED automatically by the operator
    # - Write the VRL function as plain text here
    # - Operator will handle base64 encoding when sending to API
    # - Transforms each result row before alert evaluation
    # - Can add/modify/remove fields from results
    vrlFunction: |
      .processed_at = now()
      .alert_severity = if .error_count > 100 {
        "critical"
      } else if .error_count > 50 {
        "warning"
      } else {
        "info"
      }
      .needs_immediate_action = .error_count > 100

    # ==========================================
    # OPTION 3: PROMQL QUERY TYPE
    # Use for Prometheus-compatible metric queries
    # ==========================================

    # PromQL query (Required for promql type, empty string otherwise)
    # - Only works with streamType: "metrics"
    # - Standard PromQL syntax
    # - Supports all PromQL functions and operators
    # - Time ranges in brackets: [5m], [1h], [1d]
    promql: |
      # CPU usage above 80% for 5 minutes
      avg(rate(cpu_usage_seconds_total[5m])) by (instance) > 0.8

      # OR: Memory usage above 90%
      # (node_memory_MemTotal_bytes - node_memory_MemFree_bytes) / node_memory_MemTotal_bytes > 0.9

      # OR: HTTP error rate above 1%
      # sum(rate(http_requests_total{status=~"5.."}[5m])) / sum(rate(http_requests_total[5m])) > 0.01

    # ==========================================
    # MULTI TIME RANGE (Optional)
    # Compare data across multiple time windows
    # ==========================================
    # - Useful for detecting trends or anomalies
    # - Each offset creates a separate query result
    # - Pattern: ^[0-9]+(m|h|d)$ where m=minutes, h=hours, d=days
    multiTimeRange:
      - offset: "30m"    # 30 minutes ago
      - offset: "1h"     # 1 hour ago
      - offset: "3h"     # 3 hours ago
      - offset: "6h"     # 6 hours ago
      - offset: "1d"     # 1 day ago
      - offset: "7d"     # 1 week ago

  # ============================================================================
  # TRIGGER CONDITION (Required)
  # Defines when and how the alert should fire
  # ============================================================================
  triggerCondition:
    # Evaluation frequency (Required)
    # - How often to run the query
    # - Range: 1-1440 (depends on frequencyType)
    # - For real-time alerts, typically set to 1 minute
    frequency: 5

    # Frequency unit (Optional, defaults to "minutes")
    # - "minutes": Check every N minutes (max 1440 = 24 hours)
    # - "hours": Check every N hours (max 24)
    # - "days": Check every N days (max 30)
    frequencyType: "minutes"

    # Look-back period in minutes (Optional, defaults to frequency)
    # - Time window to query (e.g., last 15 minutes of data)
    # - Should be >= frequency to avoid gaps in monitoring
    # - Maximum: 1440 minutes (24 hours)
    # - Example: frequency=5, period=15 means "check every 5 minutes for events in the last 15 minutes"
    period: 15

    # Threshold value (Optional, defaults to 0)
    # - Number that triggers the alert when compared with query results
    # - For count queries: number of matching records
    # - For numeric queries: the computed value
    # - For PromQL: the metric value
    threshold: 10

    # Comparison operator (Optional, defaults to ">=")
    # - How to compare query results against threshold
    # - Options: =, !=, >, >=, <, <=
    # - Example: ">= 10" means alert when result is 10 or more
    operator: ">="

    # Silence period in minutes (Optional, defaults to 0)
    # - Prevents re-triggering for this duration after alert fires
    # - Reduces alert fatigue for flapping conditions
    # - Maximum: 10080 minutes (7 days)
    # - 0 means alert can fire again immediately
    silence: 30

    # Timezone for scheduling (Optional, defaults to "UTC")
    # - IANA timezone format
    # - Examples: "UTC", "America/New_York", "Europe/London", "Asia/Tokyo"
    # - Affects cron schedule and time-based queries
    timezone: "UTC"

    # Align evaluation to time boundaries (Optional, defaults to false)
    # - true: Runs at exact intervals (e.g., :00, :15, :30, :45)
    # - false: Runs at frequency intervals from start time
    # - Useful for predictable evaluation times
    alignTime: true

    # Cron expression (Optional, alternative to frequency/frequencyType)
    # - Standard Unix cron format: "minute hour day month weekday"
    # - Overrides frequency/frequencyType if specified
    # - Examples:
    #   * "0 * * * *"     - Every hour at minute 0
    #   * "*/5 * * * *"   - Every 5 minutes
    #   * "0 9-17 * * 1-5" - Every hour 9am-5pm on weekdays
    #   * "0 0 * * 0"     - Weekly on Sunday at midnight
    cron: ""

    # Tolerance in seconds (Optional)
    # - Maximum delay allowed for scheduled evaluation
    # - Useful for handling processing delays
    toleranceInSecs: null

  # ============================================================================
  # DEDUPLICATION (Optional)
  # Prevents duplicate alerts for the same issue
  # ============================================================================
  deduplication:
    # Enable deduplication (Required if deduplication block present)
    # NOTE: Field name is "enabled" in YAML and API
    enabled: true

    # Fields to create fingerprint (Required when enabled=true)
    # - Alerts with identical values in these fields are considered duplicates
    # - Common fields: host, service, error_type, region
    # - Special field "_timestamp" groups by time window
    # - Order matters: ["host", "service"] != ["service", "host"]
    fingerprintFields:
      - "host"           # Group by host machine
      - "service"        # Group by service name
      - "error_code"     # Group by specific error
      # - "_timestamp"   # Use for time-based grouping

    # Time window for deduplication in minutes (Optional)
    # - Only one alert per fingerprint within this window
    # - Defaults to alert period if not specified
    # - Example: 60 = suppress duplicates for 1 hour
    timeWindowMinutes: 60

  # ============================================================================
  # DESTINATIONS (Required)
  # Where to send alert notifications
  # ============================================================================
  # - Must have 1-10 destinations
  # - Destinations must exist in OpenObserve
  # - Types: slack, email, webhook, pagerduty, teams, etc.
  # - Configured separately in OpenObserve UI
  destinations:
    - "slack_critical"      # Slack channel for critical alerts
    - "email_oncall"        # Email distribution list
    - "pagerduty_p1"        # PagerDuty for P1 incidents
    - "webhook_monitoring"  # Custom webhook endpoint

  # ============================================================================
  # CONTEXT ATTRIBUTES (Optional)
  # Additional metadata attached to alert notifications
  # ============================================================================
  # - Enriches alerts with static metadata
  # - Used for routing, filtering, or providing context
  # - All three fields are required for each attribute
  # - Maximum 20 attributes per alert
  contextAttributes:
    - name: "environment"      # Human-readable name
      value: "production"       # Attribute value (string)
      key: "env"               # Internal key for templates

    - name: "team"
      value: "platform-engineering"
      key: "team_name"

    - name: "severity"
      value: "critical"
      key: "severity_level"

    - name: "sla"
      value: "99.99"
      key: "sla_percentage"

    - name: "cost_center"
      value: "engineering-123"
      key: "cost_center_id"

  # ============================================================================
  # ROW TEMPLATE (Optional)
  # Formats alert notification messages
  # ============================================================================

  # Template string with field placeholders
  # - Use {{field_name}} to reference:
  #   * Fields from query results
  #   * Context attributes using their keys
  #   * Built-in fields: _timestamp, _count, etc.
  # - Supports basic string interpolation only (no conditionals)
  # - Examples by alert type:
  rowTemplate: |
    ðŸš¨ Alert: {{level}} error detected
    Service: {{service}}
    Host: {{host}}
    Error Count: {{_count}}
    Environment: {{env}}
    Time: {{_timestamp}}
    Action: Check {{service}} logs on {{host}}

  # Template type (Optional, defaults to "String")
  # - "String": Plain text with variable substitution
  # - "JSON": Structured JSON output (for webhook destinations)
  rowTemplateType: "String"

  # ============================================================================
  # TIMEZONE OFFSET (Optional)
  # Additional timezone configuration
  # ============================================================================
  # - Offset in minutes from UTC
  # - Alternative to timezone string
  # - Example: -300 for EST (UTC-5)
  tzOffset: null

# ============================================================================
# VALIDATION RULES AND CONSTRAINTS
# ============================================================================
#
# GENERAL RULES:
# 1. Alert name: No spaces, only [a-zA-Z0-9_-] characters
# 2. All string values should be quoted for safety
# 3. Numeric values can be quoted or unquoted
#
# QUERY TYPE RULES:
# 4. SQL type:
#    - Requires non-empty SQL query
#    - Can use VRL function (automatically base64 encoded)
#    - conditions field should be null
# 5. PromQL type:
#    - Requires streamType: "metrics"
#    - Requires non-empty PromQL query
#    - conditions field should be null
#    - Cannot use VRL function
# 6. Custom type:
#    - SQL and PromQL must be empty strings
#    - Can use conditions and/or aggregation
#    - Cannot use VRL function
#
# REAL-TIME ALERT RULES:
# 7. When isRealTime: true
#    - Query type must be "custom"
#    - Aggregation must be null
#    - Triggers immediately on match
#
# FIELD INTERACTIONS:
# 8. folderName takes precedence over folderId if both specified
# 9. Period should be >= frequency to ensure complete coverage
# 10. Deduplication timeWindow defaults to period if not specified
#
# LIMITS:
# 11. Destinations: 1-10 required
# 12. Frequency: 1-1440 (depends on unit)
# 13. Period: Maximum 1440 minutes
# 14. Silence: Maximum 10080 minutes
# 15. Description: Maximum 1000 characters
# 16. Context attributes: Maximum 20
#
# SPECIAL FIELDS:
# 17. _timestamp: Built-in field for event time
# 18. _count: Result of count aggregation
# 19. _source: Original log source
#
# API FIELD MAPPINGS (handled by operator):
# 20. YAML "enabled" -> API "enabled" (for deduplication)
# 21. YAML "fingerprintFields" -> API "fingerprint_fields"
# 22. YAML "timeWindowMinutes" -> API "time_window_minutes"
# 23. VRL functions are base64 encoded for SQL queries

# ============================================================================
# COMPLETE EXAMPLES
# ============================================================================

---
# Example 1: High Error Rate Alert with Aggregation
apiVersion: openobserve.ai/v1alpha1
kind: OpenObserveAlert
metadata:
  name: high-error-rate-aggregated
  namespace: monitoring
spec:
  configRef:
    name: openobserve-main
    namespace: monitoring

  name: "high_error_rate_by_service"
  description: "Alerts when any service exceeds 100 errors in 5 minutes"
  streamName: "application_logs"
  streamType: "logs"
  enabled: true
  isRealTime: false

  folderName: "production_alerts"

  queryCondition:
    type: "custom"
    aggregation:
      groupBy: ["service", "environment"]
      function: "count"
      having:
        column: "_count"
        operator: ">="
        value: 100
    conditions:
      label: "and"
      items:
        - column: "level"
          operator: "="
          value: "ERROR"
          ignoreCase: false
        - column: "environment"
          operator: "="
          value: "production"

  triggerCondition:
    frequency: 5
    frequencyType: "minutes"
    period: 5
    threshold: 1
    operator: ">="
    silence: 30
    timezone: "UTC"
    alignTime: true

  deduplication:
    enabled: true
    fingerprintFields:
      - "service"
      - "environment"
    timeWindowMinutes: 60

  destinations:
    - "slack_critical"
    - "pagerduty"

  contextAttributes:
    - name: "severity"
      value: "high"
      key: "severity"
    - name: "team"
      value: "backend"
      key: "team"

  rowTemplate: "ðŸ”´ High error rate in {{service}} ({{environment}}): {{_count}} errors in last 5 minutes"
  rowTemplateType: "String"

---
# Example 2: Complex SQL Query with VRL Transformation
apiVersion: openobserve.ai/v1alpha1
kind: OpenObserveAlert
metadata:
  name: api-latency-p99
  namespace: monitoring
spec:
  configRef:
    name: openobserve-main

  name: "api_latency_p99_alert"
  description: "Monitors API P99 latency and alerts on degradation"
  streamName: "api_metrics"
  streamType: "logs"

  queryCondition:
    type: "sql"
    sql: |
      WITH latency_stats AS (
        SELECT
          endpoint,
          method,
          PERCENTILE_CONT(0.99) WITHIN GROUP (ORDER BY duration_ms) as p99_latency,
          PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY duration_ms) as p95_latency,
          COUNT(*) as request_count,
          AVG(duration_ms) as avg_latency
        FROM stream
        WHERE
          _timestamp >= now() - INTERVAL '10 minutes'
          AND endpoint NOT LIKE '%health%'
        GROUP BY endpoint, method
      )
      SELECT *
      FROM latency_stats
      WHERE p99_latency > 1000
      ORDER BY p99_latency DESC

    vrlFunction: |
      .severity = if .p99_latency > 5000 {
        "critical"
      } else if .p99_latency > 2000 {
        "warning"
      } else {
        "info"
      }
      .breach_percentage = (.p99_latency - 1000) / 1000 * 100
      .requires_scaling = .request_count > 10000 && .p99_latency > 2000

  triggerCondition:
    frequency: 2
    frequencyType: "minutes"
    period: 10
    threshold: 1
    operator: ">="
    silence: 15

  destinations:
    - "api_team_slack"
    - "performance_webhook"

  rowTemplate: "API Latency Alert: {{endpoint}} {{method}} - P99: {{p99_latency}}ms ({{severity}})"

---
# Example 3: PromQL Metrics Alert for Kubernetes
apiVersion: openobserve.ai/v1alpha1
kind: OpenObserveAlert
metadata:
  name: k8s-pod-cpu-throttling
  namespace: monitoring
spec:
  configRef:
    name: openobserve-main

  name: "kubernetes_cpu_throttling"
  description: "Detects CPU throttling in Kubernetes pods"
  streamName: "kubernetes_metrics"
  streamType: "metrics"

  queryCondition:
    type: "promql"
    promql: |
      sum by (namespace, pod) (
        rate(container_cpu_cfs_throttled_periods_total[5m])
      ) / sum by (namespace, pod) (
        rate(container_cpu_cfs_periods_total[5m])
      ) > 0.25

  triggerCondition:
    frequency: 1
    frequencyType: "minutes"
    period: 5
    threshold: 0.25
    operator: ">"
    silence: 30
    alignTime: true

  destinations:
    - "k8s_alerts"

  contextAttributes:
    - name: "cluster"
      value: "production-us-west-2"
      key: "cluster"
    - name: "alert_type"
      value: "performance"
      key: "type"

  rowTemplate: "Pod CPU throttling detected: {{namespace}}/{{pod}} - {{value}}% of periods throttled"

---
# Example 4: Real-time Security Alert with Multi-condition
apiVersion: openobserve.ai/v1alpha1
kind: OpenObserveAlert
metadata:
  name: security-breach-realtime
  namespace: security
spec:
  configRef:
    name: openobserve-main

  name: "realtime_security_breach"
  description: "Immediate alert on potential security breaches"
  streamName: "security_events"
  streamType: "logs"
  enabled: true
  isRealTime: true  # Real-time processing

  queryCondition:
    type: "custom"
    aggregation: null  # Must be null for real-time
    conditions:
      # Nested OR conditions for complex security rules
      # This triggers if: authentication_failed OR privilege_escalation OR (threat_score >= 8 AND source_ip contains suspicious_list)
      or:
        - column: "event_type"
          operator: "="
          value: "authentication_failed"
          ignore_case: false
        - column: "event_type"
          operator: "="
          value: "privilege_escalation"
          ignore_case: false
        - and:  # Nested AND condition - both must be true
            - column: "threat_score"
              operator: ">="
              value: "8"
              ignore_case: false
            - column: "source_ip"
              operator: "contains"
              value: "suspicious_list"
              ignore_case: false

  triggerCondition:
    frequency: 1
    frequencyType: "minutes"
    period: 1
    threshold: 1
    operator: ">="
    silence: 5  # Short silence for critical alerts

  deduplication:
    enabled: true
    fingerprintFields:
      - "source_ip"
      - "target_user"
      - "event_type"
    timeWindowMinutes: 30

  destinations:
    - "security_pager"
    - "siem_webhook"
    - "security_slack"

  contextAttributes:
    - name: "priority"
      value: "P0"
      key: "priority"
    - name: "response_required"
      value: "immediate"
      key: "response"

  rowTemplate: |
    ðŸš¨ SECURITY ALERT ðŸš¨
    Type: {{event_type}}
    User: {{target_user}}
    Source: {{source_ip}}
    Score: {{threat_score}}
    Time: {{_timestamp}}
    Action: IMMEDIATE INVESTIGATION REQUIRED

---
# Example 5: Multi-Time Range Comparison Alert
apiVersion: openobserve.ai/v1alpha1
kind: OpenObserveAlert
metadata:
  name: traffic-anomaly-detection
  namespace: monitoring
spec:
  configRef:
    name: openobserve-main

  name: "traffic_anomaly_detector"
  description: "Detects unusual traffic patterns compared to historical data"
  streamName: "nginx_logs"
  streamType: "logs"

  queryCondition:
    type: "custom"
    aggregation:
      groupBy: ["endpoint"]
      function: "count"
    conditions:
      label: "and"
      items:
        - column: "status_code"
          operator: ">="
          value: "200"
        - column: "status_code"
          operator: "<"
          value: "300"
    multiTimeRange:
      - offset: "1h"   # Current hour
      - offset: "1d"   # Same hour yesterday
      - offset: "7d"   # Same hour last week

  triggerCondition:
    frequency: 15
    frequencyType: "minutes"
    period: 60
    threshold: 2  # Threshold is 2x historical average
    operator: ">"
    silence: 60

  destinations:
    - "traffic_alerts"

  rowTemplate: "Traffic anomaly on {{endpoint}}: Current {{_count}} requests (2x above normal)"

---
# Example 6: Scheduled Report Alert with Cron
apiVersion: openobserve.ai/v1alpha1
kind: OpenObserveAlert
metadata:
  name: daily-error-summary
  namespace: monitoring
spec:
  configRef:
    name: openobserve-main

  name: "daily_error_report"
  description: "Daily summary of errors by service"
  streamName: "application_logs"
  streamType: "logs"

  queryCondition:
    type: "sql"
    sql: |
      SELECT
        service,
        error_type,
        COUNT(*) as error_count,
        COUNT(DISTINCT user_id) as affected_users,
        MIN(_timestamp) as first_occurrence,
        MAX(_timestamp) as last_occurrence
      FROM stream
      WHERE
        level = 'ERROR'
        AND _timestamp >= now() - INTERVAL '24 hours'
      GROUP BY service, error_type
      ORDER BY error_count DESC
      LIMIT 50

  triggerCondition:
    frequency: 1  # Ignored when cron is set
    frequencyType: "days"
    period: 1440  # 24 hours
    threshold: 1
    operator: ">="
    cron: "0 9 * * *"  # Every day at 9 AM
    timezone: "America/New_York"
    alignTime: false  # Not needed with cron

  destinations:
    - "daily_reports_email"
    - "manager_slack"

  rowTemplate: "Daily Error Summary: {{service}} - {{error_type}}: {{error_count}} errors affecting {{affected_users}} users"
  rowTemplateType: "String"

# ============================================================================
# TROUBLESHOOTING GUIDE
# ============================================================================
#
# COMMON ISSUES AND SOLUTIONS:
#
# 1. "Alert name contains spaces" Error:
#    - Solution: Use underscores or hyphens instead of spaces
#    - Bad: "My Alert Name"
#    - Good: "my_alert_name" or "my-alert-name"
#
# 2. "Stream not found" Error:
#    - Solution: Ensure stream exists in OpenObserve
#    - Or set environment variable SKIP_STREAM_VALIDATION=true
#
# 3. "Invalid query type for metrics stream":
#    - Solution: Use "promql" type for metrics streams
#    - Custom and SQL types don't work with metrics
#
# 4. "Aggregation not null for realtime alert":
#    - Solution: Set aggregation to null for real-time alerts
#    - Real-time alerts cannot use grouping or aggregation
#
# 5. "Deduplication requires fingerprint fields":
#    - Solution: Add at least one field to fingerprintFields
#    - Common fields: host, service, error_type
#
# 6. "Base64 decode error" for VRL function:
#    - Issue: VRL functions are automatically base64 encoded by operator
#    - Solution: Write VRL as plain text in YAML, operator handles encoding
#
# 7. "Conditions should be null for SQL/PromQL":
#    - Solution: Set conditions to null or omit for SQL/PromQL types
#    - Conditions are only for custom query type
#
# 8. Alert not triggering:
#    - Check: Is enabled: true?
#    - Check: Is threshold correctly set?
#    - Check: Is silence period still active?
#    - Check: Does query return expected results?
#
# 9. Too many duplicate alerts:
#    - Solution: Enable deduplication with appropriate fingerprint fields
#    - Adjust timeWindowMinutes to suppress duplicates longer
#
# 10. Timezone issues:
#     - Solution: Use IANA timezone format (e.g., "America/New_York")
#     - Or use tzOffset for minute offset from UTC

# ============================================================================
# END OF TEMPLATE
# ============================================================================